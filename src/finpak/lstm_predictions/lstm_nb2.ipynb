{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from finpak.data.fetchers.yahoo import download_multiple_tickers\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# Use this device throughout your code\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([225.88999939, 226.50999451, 226.3999939 , 224.52999878,\n",
       "       226.83999634, 227.17999268, 228.02999878, 226.49000549,\n",
       "       229.78999329, 229.        ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL']\n",
    "start_date = '2000-04-01'\n",
    "end_date = '2024-08-31'\n",
    "\n",
    "# Download historical data for the tickers\n",
    "data_df = download_multiple_tickers(tickers, start_date, end_date)\n",
    "data_df = data_df.loc[:,'Adj Close'] # Extract from multi-index dataframe\n",
    "data_df.tail(8)\n",
    "\n",
    "\n",
    "data_df.head(2)\n",
    "\n",
    "\n",
    "data_df['AAPL'].values[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([225.88999939, 226.50999451, 226.3999939 , 224.52999878,\n",
       "       226.83999634, 227.17999268, 228.02999878, 226.49000549,\n",
       "       229.78999329, 229.        ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices = data_df['AAPL'].values \n",
    "prices[-10:]\n",
    "\n",
    "\n",
    "# # Calculate percentage changes\n",
    "# pct_changes = np.diff(prices) / prices[:-1]\n",
    "\n",
    "# # Optionally adjust by volatility\n",
    "# adjust_by_volatility = False # True\n",
    "# if adjust_by_volatility:\n",
    "#     volatility = np.std(pct_changes)\n",
    "#     pct_changes = pct_changes / volatility\n",
    "\n",
    "\n",
    "# pct_changes[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- **Create Sequences:**\n",
    "  - Decide on a sequence length (e.g., 50).\n",
    "  - Convert the percentage changes into input-output pairs where each input is a sequence of `sequence_length` steps, and the output is the next value.\n",
    "\"\"\"\n",
    "\n",
    "# After downloading the data\n",
    "\n",
    "def calculate_features(prices):\n",
    "    # 1-day percentage change\n",
    "    pct_change_1d = np.diff(prices) / prices[:-1]\n",
    "    pct_change_1d = np.insert(pct_change_1d, 0, 0)  # Insert 0 at the beginning for alignment\n",
    "    \n",
    "    # Percentage difference from 30-day moving average\n",
    "    ma_30 = pd.Series(prices).rolling(window=30).mean()\n",
    "    pct_diff_ma30 = (prices - ma_30) / ma_30\n",
    "    \n",
    "    # 5-day percentage change\n",
    "    pct_change_5d = (prices[5:] - prices[:-5]) / prices[:-5]\n",
    "    pct_change_5d = np.pad(pct_change_5d, (5, 0), mode='constant', constant_values=0)\n",
    "    \n",
    "    # 15-day percentage change\n",
    "    pct_change_15d = (prices[15:] - prices[:-15]) / prices[:-15]\n",
    "    pct_change_15d = np.pad(pct_change_15d, (15, 0), mode='constant', constant_values=0)\n",
    "    \n",
    "    return np.column_stack((pct_change_1d, pct_diff_ma30, pct_change_5d, pct_change_15d))\n",
    "\n",
    "# Calculate features\n",
    "features = calculate_features(prices)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Create sequences\n",
    "sequence_length = 10\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(scaled_features) - sequence_length):\n",
    "    X.append(scaled_features[i:i + sequence_length])\n",
    "    y.append(scaled_features[i + sequence_length, 0])  # Still predicting 1-day percentage change\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust for 30-day moving average\n",
    "X = X[30:]\n",
    "y = y[30:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.86999057, -1.49905685, -0.06743923, -2.11510724],\n",
       "        [-1.73652598, -1.89912034,  0.28575537, -1.98479921],\n",
       "        [-0.30412708, -1.87230219, -0.4981022 , -2.42838803],\n",
       "        [-2.81971483, -2.54555765, -2.54348646, -2.83292709],\n",
       "        [-1.83640201, -2.8858714 , -2.21582963, -3.2049885 ],\n",
       "        [-1.94581077, -3.24999036, -3.72339521, -3.15585151],\n",
       "        [ 0.85434742, -2.92972937, -2.70518106, -2.78503818],\n",
       "        [-0.24813835, -2.91067053, -2.68255723, -2.49883621],\n",
       "        [-0.47122499, -2.93056074, -1.67033229, -2.76926462],\n",
       "        [ 0.51936111, -2.70760036, -0.61993824, -2.42570357]]),\n",
       " np.float64(-1.7316410359523122))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = torch.tensor(sequences, dtype=torch.float32).to(device)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float32).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.targets[idx]\n",
    "\n",
    "\n",
    "class SwishActivation(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "class LSTMLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTMLayer, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.swish = SwishActivation()\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.layer_norm(out)\n",
    "        out = self.swish(out)\n",
    "        return out, hidden\n",
    "\n",
    "class EnhancedLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden_size=2048, num_layers=3):\n",
    "        super(EnhancedLSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            LSTMLayer(input_size if i == 0 else hidden_size, hidden_size)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.inner_fc = nn.Linear(hidden_size, hidden_size)\n",
    "        self.inner_ln = nn.LayerNorm(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.layer_norm_final = nn.LayerNorm(hidden_size)\n",
    "        self.swish = SwishActivation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(1, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(1, batch_size, self.hidden_size).to(x.device)\n",
    "        hidden = (h0, c0)\n",
    "\n",
    "        residual = None\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i == 0:\n",
    "                out, hidden = layer(x, hidden)\n",
    "            else:\n",
    "                layer_input = out if residual is None else out + residual\n",
    "                out, hidden = layer(layer_input, hidden)\n",
    "            \n",
    "            if i > 0:  # Apply residual connection for all layers except the first\n",
    "                residual = out\n",
    "\n",
    "        out = self.layer_norm_final(out)\n",
    "        out = self.swish(out)\n",
    "        out = self.inner_fc(out)\n",
    "        out = self.inner_ln(out)\n",
    "        out = self.swish(out)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the full dataset\n",
    "full_dataset = StockDataset(X, y)\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.88\n",
    "val_ratio = 0.12\n",
    "\n",
    "# Calculate split indices\n",
    "train_size = int(len(y) * train_ratio)\n",
    "val_size = int(len(y) * val_ratio)\n",
    "\n",
    "# Split the dataset sequentially\n",
    "train_dataset = torch.utils.data.Subset(full_dataset, range(train_size))\n",
    "val_dataset = torch.utils.data.Subset(full_dataset, range(train_size, train_size + val_size))\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedLSTMModel(input_size=4, hidden_size=888, num_layers=4).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00053)\n",
    "best_val_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/225]\n",
      "Train Loss: 1.1783\n",
      "Validation Loss: 0.5192\n",
      "New best model saved!\n",
      "--------------------------------------------------\n",
      "Epoch [2/225]\n",
      "Train Loss: 1.0585\n",
      "Validation Loss: 0.5141\n",
      "New best model saved!\n",
      "--------------------------------------------------\n",
      "Epoch [3/225]\n",
      "Train Loss: 1.0543\n",
      "Validation Loss: 0.5161\n",
      "--------------------------------------------------\n",
      "Epoch [4/225]\n",
      "Train Loss: 1.0542\n",
      "Validation Loss: 0.5181\n",
      "--------------------------------------------------\n",
      "Epoch [5/225]\n",
      "Train Loss: 1.0545\n",
      "Validation Loss: 0.5161\n",
      "--------------------------------------------------\n",
      "Epoch [6/225]\n",
      "Train Loss: 1.0541\n",
      "Validation Loss: 0.5156\n",
      "--------------------------------------------------\n",
      "Epoch [7/225]\n",
      "Train Loss: 1.0540\n",
      "Validation Loss: 0.5152\n",
      "--------------------------------------------------\n",
      "Epoch [8/225]\n",
      "Train Loss: 1.0537\n",
      "Validation Loss: 0.5153\n",
      "--------------------------------------------------\n",
      "Epoch [9/225]\n",
      "Train Loss: 1.0535\n",
      "Validation Loss: 0.5150\n",
      "--------------------------------------------------\n",
      "Epoch [10/225]\n",
      "Train Loss: 1.0532\n",
      "Validation Loss: 0.5157\n",
      "--------------------------------------------------\n",
      "Epoch [11/225]\n",
      "Train Loss: 1.0536\n",
      "Validation Loss: 0.5157\n",
      "--------------------------------------------------\n",
      "Epoch [12/225]\n",
      "Train Loss: 1.0537\n",
      "Validation Loss: 0.5169\n",
      "--------------------------------------------------\n",
      "Epoch [13/225]\n",
      "Train Loss: 1.0542\n",
      "Validation Loss: 0.5155\n",
      "--------------------------------------------------\n",
      "Epoch [14/225]\n",
      "Train Loss: 1.0535\n",
      "Validation Loss: 0.5158\n",
      "--------------------------------------------------\n",
      "Epoch [15/225]\n",
      "Train Loss: 1.0532\n",
      "Validation Loss: 0.5167\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(sequences)\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m epoch_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/venvs/finpak/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/finpak/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/finpak/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 225\n",
    "patience = 25  # For early stopping\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for sequences, targets in train_loader:\n",
    "        sequences, targets = sequences.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in val_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "            outputs = model(sequences)\n",
    "            val_loss = criterion(outputs, targets)\n",
    "            epoch_val_loss += val_loss.item()\n",
    "    \n",
    "    avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "    print(f'Train Loss: {avg_train_loss:.4f}')\n",
    "    print(f'Validation Loss: {avg_val_loss:.4f}')\n",
    "    \n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        # When saving the model, move it to CPU first\n",
    "        torch.save(model.to('cpu').state_dict(), 'best_lstm_model.pth')\n",
    "        model.to(device)  # Move it back to the device if you continue training\n",
    "        print(\"New best model saved!\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "    \n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for EnhancedLSTMModel:\n\tMissing key(s) in state_dict: \"layers.2.lstm.weight_ih_l0\", \"layers.2.lstm.weight_hh_l0\", \"layers.2.lstm.bias_ih_l0\", \"layers.2.lstm.bias_hh_l0\", \"layers.2.layer_norm.weight\", \"layers.2.layer_norm.bias\". \n\tsize mismatch for layers.0.lstm.weight_ih_l0: copying a param with shape torch.Size([32768, 4]) from checkpoint, the shape in current model is torch.Size([8192, 4]).\n\tsize mismatch for layers.0.lstm.weight_hh_l0: copying a param with shape torch.Size([32768, 8192]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n\tsize mismatch for layers.0.lstm.bias_ih_l0: copying a param with shape torch.Size([32768]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for layers.0.lstm.bias_hh_l0: copying a param with shape torch.Size([32768]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for layers.0.layer_norm.weight: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layers.0.layer_norm.bias: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layers.1.lstm.weight_ih_l0: copying a param with shape torch.Size([32768, 8192]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n\tsize mismatch for layers.1.lstm.weight_hh_l0: copying a param with shape torch.Size([32768, 8192]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n\tsize mismatch for layers.1.lstm.bias_ih_l0: copying a param with shape torch.Size([32768]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for layers.1.lstm.bias_hh_l0: copying a param with shape torch.Size([32768]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for layers.1.layer_norm.weight: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layers.1.layer_norm.bias: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([1, 8192]) from checkpoint, the shape in current model is torch.Size([1, 2048]).\n\tsize mismatch for layer_norm_final.weight: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer_norm_final.bias: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m**Objective:** Use the trained model to make predictions, compare them with actual stock prices, and visualize the results.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m- **Load the Trained Model:**\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m EnhancedLSTMModel(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_lstm_model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m- **Autoregressive Prediction:**\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/finpak/lib/python3.12/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for EnhancedLSTMModel:\n\tMissing key(s) in state_dict: \"layers.2.lstm.weight_ih_l0\", \"layers.2.lstm.weight_hh_l0\", \"layers.2.lstm.bias_ih_l0\", \"layers.2.lstm.bias_hh_l0\", \"layers.2.layer_norm.weight\", \"layers.2.layer_norm.bias\". \n\tsize mismatch for layers.0.lstm.weight_ih_l0: copying a param with shape torch.Size([32768, 4]) from checkpoint, the shape in current model is torch.Size([8192, 4]).\n\tsize mismatch for layers.0.lstm.weight_hh_l0: copying a param with shape torch.Size([32768, 8192]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n\tsize mismatch for layers.0.lstm.bias_ih_l0: copying a param with shape torch.Size([32768]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for layers.0.lstm.bias_hh_l0: copying a param with shape torch.Size([32768]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for layers.0.layer_norm.weight: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layers.0.layer_norm.bias: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layers.1.lstm.weight_ih_l0: copying a param with shape torch.Size([32768, 8192]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n\tsize mismatch for layers.1.lstm.weight_hh_l0: copying a param with shape torch.Size([32768, 8192]) from checkpoint, the shape in current model is torch.Size([8192, 2048]).\n\tsize mismatch for layers.1.lstm.bias_ih_l0: copying a param with shape torch.Size([32768]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for layers.1.lstm.bias_hh_l0: copying a param with shape torch.Size([32768]) from checkpoint, the shape in current model is torch.Size([8192]).\n\tsize mismatch for layers.1.layer_norm.weight: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layers.1.layer_norm.bias: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([1, 8192]) from checkpoint, the shape in current model is torch.Size([1, 2048]).\n\tsize mismatch for layer_norm_final.weight: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer_norm_final.bias: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048])."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "**Objective:** Use the trained model to make predictions, compare them with actual stock prices, and visualize the results.\n",
    "\n",
    "- **Load the Trained Model:**\n",
    "\"\"\"\n",
    "\n",
    "model = EnhancedLSTMModel(input_size=4, hidden_size=2048, num_layers=3).to(device)\n",
    "model.load_state_dict(torch.load('best_lstm_model.pth', weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "- **Autoregressive Prediction:**\n",
    "\"\"\"\n",
    "\n",
    "# After loading the model and setting it to eval mode\n",
    "\n",
    "# Define the validation set range\n",
    "val_start = train_size + 30 # 30-day moving average\n",
    "val_end = train_size + val_size + 30 # 30-day moving average\n",
    "\n",
    "# Define prediction parameters\n",
    "prediction_length = 20  # Number of future steps to predict\n",
    "prediction_interval = 50  # Space between prediction start points\n",
    "\n",
    "# Function to make predictions\n",
    "def make_prediction(start_idx):\n",
    "    input_seq = scaled_features[start_idx:start_idx + sequence_length]\n",
    "    input_seq = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(prediction_length):\n",
    "            pred = model(input_seq)\n",
    "            predictions.append(pred.item())\n",
    "            \n",
    "            # Update input sequence for next prediction\n",
    "            last_features = input_seq[0, -1, :].cpu().numpy()\n",
    "            new_features = calculate_features(np.array([prices[start_idx + sequence_length - 1] * (1 + pred.item())]))[-1]\n",
    "            new_features = scaler.transform(new_features.reshape(1, -1))\n",
    "            new_input = torch.tensor(new_features, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            input_seq = torch.cat((input_seq[:, 1:], new_input), dim=1)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1 and the array at index 2 has size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Make predictions at intervals\u001b[39;00m\n\u001b[1;32m      2\u001b[0m prediction_starts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(val_start, val_end \u001b[38;5;241m-\u001b[39m sequence_length \u001b[38;5;241m-\u001b[39m prediction_length, prediction_interval)\n\u001b[0;32m----> 3\u001b[0m all_predictions \u001b[38;5;241m=\u001b[39m [\u001b[43mmake_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m start \u001b[38;5;129;01min\u001b[39;00m prediction_starts]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Denormalize predictions and prepare for plotting\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_prediction_data\u001b[39m(predictions, start_idx):\n",
      "Cell \u001b[0;32mIn[17], line 39\u001b[0m, in \u001b[0;36mmake_prediction\u001b[0;34m(start_idx)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Update input sequence for next prediction\u001b[39;00m\n\u001b[1;32m     38\u001b[0m last_features \u001b[38;5;241m=\u001b[39m input_seq[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 39\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     40\u001b[0m new_features \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(new_features\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     41\u001b[0m new_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(new_features, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m, in \u001b[0;36mcalculate_features\u001b[0;34m(prices)\u001b[0m\n\u001b[1;32m     23\u001b[0m pct_change_15d \u001b[38;5;241m=\u001b[39m (prices[\u001b[38;5;241m15\u001b[39m:] \u001b[38;5;241m-\u001b[39m prices[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m15\u001b[39m]) \u001b[38;5;241m/\u001b[39m prices[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m15\u001b[39m]\n\u001b[1;32m     24\u001b[0m pct_change_15d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(pct_change_15d, (\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m0\u001b[39m), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m, constant_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpct_change_1d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpct_diff_ma30\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpct_change_5d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpct_change_15d\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/finpak/lib/python3.12/site-packages/numpy/lib/_shape_base_impl.py:674\u001b[0m, in \u001b[0;36mcolumn_stack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    672\u001b[0m         arr \u001b[38;5;241m=\u001b[39m array(arr, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ndmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    673\u001b[0m     arrays\u001b[38;5;241m.\u001b[39mappend(arr)\n\u001b[0;32m--> 674\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1 and the array at index 2 has size 5"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions at intervals\n",
    "prediction_starts = range(val_start, val_end - sequence_length - prediction_length, prediction_interval)\n",
    "all_predictions = [make_prediction(start) for start in prediction_starts]\n",
    "\n",
    "# Denormalize predictions and prepare for plotting\n",
    "def prepare_prediction_data(predictions, start_idx):\n",
    "    denorm_predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))[:, 0]\n",
    "    last_known_price = prices[start_idx + sequence_length - 1]\n",
    "    predicted_prices = [last_known_price]\n",
    "    for pred_pct in denorm_predictions:\n",
    "        next_predicted_price = predicted_prices[-1] * (1 + pred_pct)\n",
    "        predicted_prices.append(next_predicted_price)\n",
    "    prediction_dates = pd.date_range(start=data_df.index[start_idx + sequence_length - 1], \n",
    "                                     periods=len(predicted_prices), freq='B')\n",
    "    return prediction_dates, predicted_prices\n",
    "\n",
    "# Prepare all prediction data\n",
    "all_prediction_data = [prepare_prediction_data(pred, start) \n",
    "                       for pred, start in zip(all_predictions, prediction_starts)]\n",
    "\n",
    "# Prepare actual price data for the entire validation period\n",
    "val_dates = data_df.index[val_start:val_end]\n",
    "val_prices = prices[val_start:val_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Plot actual stock price\n",
    "plt.plot(val_dates, val_prices, label='Actual Stock Price', color='blue', linewidth=2)\n",
    "\n",
    "# Plot prediction lines\n",
    "for dates, predicted_prices in all_prediction_data:\n",
    "    plt.plot(dates, predicted_prices, color='red', alpha=0.5, linewidth=1)\n",
    "\n",
    "plt.title('LSTM Model: Multiple Predictions vs Actual Stock Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Optionally, you can add a legend for predictions\n",
    "plt.plot([], [], color='red', alpha=0.5, label='Predictions')\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('lstm_predictions.png')\n",
    "plt.close()\n",
    "\n",
    "# Print some statistics\n",
    "mse = np.mean([((pred[-1] - actual) / actual) ** 2 \n",
    "               for (_, pred), actual in zip(all_prediction_data, prices[val_start + prediction_length::prediction_interval])])\n",
    "print(f\"Mean Squared Error of predictions: {mse:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Finpak",
   "language": "python",
   "name": "finpak"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
