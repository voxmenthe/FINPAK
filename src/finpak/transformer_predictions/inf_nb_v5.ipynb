{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from inference_v5 import predict_from_checkpoint # for v5 categorical inputs\n",
    "#from inference_v4 import predict_from_checkpoint # for 9h\n",
    "#from inference import predict_from_checkpoint\n",
    "from finpak.data.fetchers.yahoo import download_multiple_tickers\n",
    "from preprocessing import combine_price_series\n",
    "\n",
    "from configs import all_configs\n",
    "from ticker_configs import val_tickers_v9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n"
     ]
    }
   ],
   "source": [
    "start_date = '1990-01-01'\n",
    "end_date = '2024-12-07'\n",
    "\n",
    "val_tickers_v9 = [\n",
    "    'DIA', 'SPY', 'QQQ'\n",
    "]\n",
    "\n",
    "# Download historical data for the tickers\n",
    "#data_df = download_multiple_tickers(val_tickers_v3, start_date, end_date)\n",
    "data_df = download_multiple_tickers(val_tickers_v9, start_date, end_date)\n",
    "data_df = data_df.loc[:,'Adj Close'] # Extract from multi-index dataframe\n",
    "\n",
    "\n",
    "# Extract price series for all tickers and convert to tensors\n",
    "price_series_list = []\n",
    "for ticker in val_tickers_v9:\n",
    "    prices = data_df[ticker]\n",
    "    price_tensor = torch.tensor(prices.to_numpy(), dtype=torch.float32)\n",
    "    price_series_list.append(price_tensor)\n",
    "\n",
    "# Combine price series\n",
    "combined_prices = combine_price_series(price_series_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>DIA</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>SPY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-29</th>\n",
       "      <td>450.089996</td>\n",
       "      <td>509.739990</td>\n",
       "      <td>602.549988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-02</th>\n",
       "      <td>448.739990</td>\n",
       "      <td>515.289978</td>\n",
       "      <td>603.630005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-03</th>\n",
       "      <td>447.890015</td>\n",
       "      <td>516.869995</td>\n",
       "      <td>603.909973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-04</th>\n",
       "      <td>450.940002</td>\n",
       "      <td>523.260010</td>\n",
       "      <td>607.659973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-05</th>\n",
       "      <td>448.670013</td>\n",
       "      <td>521.809998</td>\n",
       "      <td>606.659973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker             DIA         QQQ         SPY\n",
       "Date                                          \n",
       "2024-11-29  450.089996  509.739990  602.549988\n",
       "2024-12-02  448.739990  515.289978  603.630005\n",
       "2024-12-03  447.890015  516.869995  603.909973\n",
       "2024-12-04  450.940002  523.260010  607.659973\n",
       "2024-12-05  448.670013  521.809998  606.659973"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test', 'vMS0001', 'vMS0002', 'vMS0003', 'vMS0003a', 'vMS0003b', 'vMS0003c', 'vMS0003d', 'vMS0004a', 'vMS0004b', 'test_fourier', 'v0', 'v000', 'v001', 'v002', 'v003', 'v004', 'v005', 'v005a', 'v006', 'v007', 'v008', 'v1', 'v1a', 'v1b', 'v2', 'vMP001a', 'vMP002a', 'vMP003a', 'vMP003b', 'vMP003c', 'vMP003d', 'vMP003e', 'vMP003h', 'vMP003hcat', 'vMP003hcatout', 'vMP004a', 'vMP005a', 'vMP006a', 'vMP007a', 'vMP008a', 'vMP009a', 'vMP009h', 'vMP009h2', 'vMLX01a', 'vMP000hcat_in_test'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_configs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'stability_threshold': 0.02,\n",
       "  'dampening_factor': 0.95,\n",
       "  'ewma_alpha': 0.85,\n",
       "  'temperature': 0.35,\n",
       "  'return_scaling': 0.55,\n",
       "  'beginning_uncertainty': 1e-05,\n",
       "  'uncertainty_growth': 1e-06,\n",
       "  'max_uncertainty_single': 0.07,\n",
       "  'max_uncertainty_multi': 0.15,\n",
       "  'uncertainty_damping': 0.99},)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_params_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"vMP009h_id_0_arc_v4_tc15_vc14_e2997_valloss_0.0000232.pt\": {\n",
      "        \"fname\": \"checkpoints/vMP009h_id_0_arc_v4_tc15_vc14_e2997_valloss_0.0000232.pt\",\n",
      "        \"inference_parameters\": {\n",
      "            \"rating\": \"very good - stays more in bounds - less directional\",\n",
      "            \"stability_threshold\": 0.02,\n",
      "            \"dampening_factor\": 0.95,\n",
      "            \"ewma_alpha\": 0.85,\n",
      "            \"temperature\": 0.05,\n",
      "            \"return_scaling\": 0.001,\n",
      "            \"beginning_uncertainty\": 1e-05,\n",
      "            \"uncertainty_growth\": 1e-06,\n",
      "            \"max_uncertainty_single\": 0.03,\n",
      "            \"max_uncertainty_multi\": 0.08,\n",
      "            \"uncertainty_damping\": 0.99\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def get_inference_params():\n",
    "    return f\"stab_thresh {STABILITY_THRESHOLD}, damp_factor {DAMPENING_FACTOR}, ewma_alpha {EWMA_ALPHA}, temp {TEMPERATURE}, return_scaling_power {RETURN_SCALING_POWER}, base_uncertainty {BASE_UNCERTAINTY}, uncertainty_growth {UNCERTAINTY_GROWTH}, max_uncertainty_single {MAX_UNCERTAINTY_SINGLE}, max_uncertainty_multi {MAX_UNCERTAINTY_MULTI}, uncertainty_damping {UNCERTAINTY_DAMPING}\"\n",
    "\n",
    "def get_params_dict():\n",
    "    pdict = { CHECKPOINT_NAME: {\n",
    "                \"fname\": CHECKPOINT_PATH,\n",
    "                \"inference_parameters\":\n",
    "                {\n",
    "                    'rating': RATING,\n",
    "                    'stability_threshold': STABILITY_THRESHOLD,\n",
    "                    'dampening_factor': DAMPENING_FACTOR,\n",
    "                    'ewma_alpha': EWMA_ALPHA,\n",
    "                    'temperature': TEMPERATURE,\n",
    "                    'return_scaling': RETURN_SCALING_POWER,\n",
    "                    'beginning_uncertainty': BASE_UNCERTAINTY,\n",
    "                    'uncertainty_growth': UNCERTAINTY_GROWTH,\n",
    "                    'max_uncertainty_single': MAX_UNCERTAINTY_SINGLE,\n",
    "                    'max_uncertainty_multi': MAX_UNCERTAINTY_MULTI,\n",
    "                    'uncertainty_damping': UNCERTAINTY_DAMPING\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    return json.dumps(pdict, indent=4)\n",
    "\n",
    "#get_inference_params()\n",
    "RATING = 'very good - stays more in bounds - less directional'\n",
    "print(get_params_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection\n",
    "CONFIG_NAME = 'vMP000hcat_in_test'\n",
    "\n",
    "CHECKPOINT_NAME = 'vMP000hcat_in_test_e26_valloss_0.0024528_tc0_vc0.pt'\n",
    "#CHECKPOINT_PATH = f'checkpoints/{CHECKPOINT_NAME}'\n",
    "CHECKPOINT_PATH = f'saved_checkpoints/{CHECKPOINT_NAME}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checkpoint keys: dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'train_loss', 'val_loss', 'metadata'])\n",
      "\n",
      "Model state dict keys:\n",
      "input_embedding.continuous_projection.weight: torch.Size([20, 13])\n",
      "input_embedding.continuous_projection.bias: torch.Size([20])\n",
      "input_embedding.categorical_embeddings.0.weight: torch.Size([10, 4])\n",
      "input_embedding.categorical_embeddings.1.weight: torch.Size([10, 4])\n",
      "input_embedding.categorical_embeddings.2.weight: torch.Size([10, 4])\n",
      "input_embedding.layer_norm.weight: torch.Size([32])\n",
      "input_embedding.layer_norm.bias: torch.Size([32])\n",
      "blocks.0.ln1.weight: torch.Size([32])\n",
      "blocks.0.ln1.bias: torch.Size([32])\n",
      "blocks.0.attention.attention_modules.0.mask: torch.Size([1, 1, 1024, 1024])\n",
      "blocks.0.attention.attention_modules.0.qkv.weight: torch.Size([96, 32])\n",
      "blocks.0.attention.attention_modules.0.qkv.bias: torch.Size([96])\n",
      "blocks.0.attention.attention_modules.0.proj.weight: torch.Size([32, 32])\n",
      "blocks.0.attention.attention_modules.0.proj.bias: torch.Size([32])\n",
      "blocks.0.attention.attention_modules.0.pos_enc.position_independent: torch.Size([8, 2])\n",
      "blocks.0.attention.scale_combine.weight: torch.Size([32, 32])\n",
      "blocks.0.attention.scale_combine.bias: torch.Size([32])\n",
      "blocks.0.ln2.weight: torch.Size([32])\n",
      "blocks.0.ln2.bias: torch.Size([32])\n",
      "blocks.0.mlp.0.weight: torch.Size([64, 32])\n",
      "blocks.0.mlp.0.bias: torch.Size([64])\n",
      "blocks.0.mlp.2.weight: torch.Size([32, 64])\n",
      "blocks.0.mlp.2.bias: torch.Size([32])\n",
      "blocks.1.ln1.weight: torch.Size([32])\n",
      "blocks.1.ln1.bias: torch.Size([32])\n",
      "blocks.1.attention.attention_modules.0.mask: torch.Size([1, 1, 1024, 1024])\n",
      "blocks.1.attention.attention_modules.0.qkv.weight: torch.Size([96, 32])\n",
      "blocks.1.attention.attention_modules.0.qkv.bias: torch.Size([96])\n",
      "blocks.1.attention.attention_modules.0.proj.weight: torch.Size([32, 32])\n",
      "blocks.1.attention.attention_modules.0.proj.bias: torch.Size([32])\n",
      "blocks.1.attention.attention_modules.0.pos_enc.position_independent: torch.Size([8, 2])\n",
      "blocks.1.attention.scale_combine.weight: torch.Size([32, 32])\n",
      "blocks.1.attention.scale_combine.bias: torch.Size([32])\n",
      "blocks.1.ln2.weight: torch.Size([32])\n",
      "blocks.1.ln2.bias: torch.Size([32])\n",
      "blocks.1.mlp.0.weight: torch.Size([64, 32])\n",
      "blocks.1.mlp.0.bias: torch.Size([64])\n",
      "blocks.1.mlp.2.weight: torch.Size([32, 64])\n",
      "blocks.1.mlp.2.bias: torch.Size([32])\n",
      "blocks.2.ln1.weight: torch.Size([32])\n",
      "blocks.2.ln1.bias: torch.Size([32])\n",
      "blocks.2.attention.attention_modules.0.mask: torch.Size([1, 1, 1024, 1024])\n",
      "blocks.2.attention.attention_modules.0.qkv.weight: torch.Size([96, 32])\n",
      "blocks.2.attention.attention_modules.0.qkv.bias: torch.Size([96])\n",
      "blocks.2.attention.attention_modules.0.proj.weight: torch.Size([32, 32])\n",
      "blocks.2.attention.attention_modules.0.proj.bias: torch.Size([32])\n",
      "blocks.2.attention.attention_modules.0.pos_enc.position_independent: torch.Size([8, 2])\n",
      "blocks.2.attention.scale_combine.weight: torch.Size([32, 32])\n",
      "blocks.2.attention.scale_combine.bias: torch.Size([32])\n",
      "blocks.2.ln2.weight: torch.Size([32])\n",
      "blocks.2.ln2.bias: torch.Size([32])\n",
      "blocks.2.mlp.0.weight: torch.Size([64, 32])\n",
      "blocks.2.mlp.0.bias: torch.Size([64])\n",
      "blocks.2.mlp.2.weight: torch.Size([32, 64])\n",
      "blocks.2.mlp.2.bias: torch.Size([32])\n",
      "blocks.3.ln1.weight: torch.Size([32])\n",
      "blocks.3.ln1.bias: torch.Size([32])\n",
      "blocks.3.attention.attention_modules.0.mask: torch.Size([1, 1, 1024, 1024])\n",
      "blocks.3.attention.attention_modules.0.qkv.weight: torch.Size([96, 32])\n",
      "blocks.3.attention.attention_modules.0.qkv.bias: torch.Size([96])\n",
      "blocks.3.attention.attention_modules.0.proj.weight: torch.Size([32, 32])\n",
      "blocks.3.attention.attention_modules.0.proj.bias: torch.Size([32])\n",
      "blocks.3.attention.attention_modules.0.pos_enc.position_independent: torch.Size([8, 2])\n",
      "blocks.3.attention.scale_combine.weight: torch.Size([32, 32])\n",
      "blocks.3.attention.scale_combine.bias: torch.Size([32])\n",
      "blocks.3.ln2.weight: torch.Size([32])\n",
      "blocks.3.ln2.bias: torch.Size([32])\n",
      "blocks.3.mlp.0.weight: torch.Size([64, 32])\n",
      "blocks.3.mlp.0.bias: torch.Size([64])\n",
      "blocks.3.mlp.2.weight: torch.Size([32, 64])\n",
      "blocks.3.mlp.2.bias: torch.Size([32])\n",
      "blocks.4.ln1.weight: torch.Size([32])\n",
      "blocks.4.ln1.bias: torch.Size([32])\n",
      "blocks.4.attention.attention_modules.0.mask: torch.Size([1, 1, 1024, 1024])\n",
      "blocks.4.attention.attention_modules.0.qkv.weight: torch.Size([96, 32])\n",
      "blocks.4.attention.attention_modules.0.qkv.bias: torch.Size([96])\n",
      "blocks.4.attention.attention_modules.0.proj.weight: torch.Size([32, 32])\n",
      "blocks.4.attention.attention_modules.0.proj.bias: torch.Size([32])\n",
      "blocks.4.attention.attention_modules.0.pos_enc.position_independent: torch.Size([8, 2])\n",
      "blocks.4.attention.scale_combine.weight: torch.Size([32, 32])\n",
      "blocks.4.attention.scale_combine.bias: torch.Size([32])\n",
      "blocks.4.ln2.weight: torch.Size([32])\n",
      "blocks.4.ln2.bias: torch.Size([32])\n",
      "blocks.4.mlp.0.weight: torch.Size([64, 32])\n",
      "blocks.4.mlp.0.bias: torch.Size([64])\n",
      "blocks.4.mlp.2.weight: torch.Size([32, 64])\n",
      "blocks.4.mlp.2.bias: torch.Size([32])\n",
      "ln_f.weight: torch.Size([32])\n",
      "ln_f.bias: torch.Size([32])\n",
      "output_projection.weight: torch.Size([3, 32])\n",
      "output_projection.bias: torch.Size([3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cw/rw396n655kx_hcjt2ldbh38r0000gn/T/ipykernel_22671/2453989607.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(CHECKPOINT_PATH, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "# Examine checkpoint structure\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location='cpu')\n",
    "print(\"\\nCheckpoint keys:\", checkpoint.keys())\n",
    "if 'config' in checkpoint:\n",
    "    print(\"\\nCheckpoint config:\", checkpoint['config'])\n",
    "print(\"\\nModel state dict keys:\")\n",
    "for k, v in checkpoint['model_state_dict'].items():\n",
    "    print(f\"{k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d_model': 32, 'n_heads': 4, 'n_layers': 8, 'd_ff': 64, 'use_multi_scale': False, 'use_relative_pos': False, 'use_hope_pos': True, 'temporal_scales': [1, 4, 6], 'd_continuous': 13, 'n_categorical': 1, 'n_bins': 10, 'n_outputs': 3}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TimeSeriesDecoder:\n\tUnexpected key(s) in state_dict: \"input_embedding.categorical_embeddings.1.weight\", \"input_embedding.categorical_embeddings.2.weight\". \n\tsize mismatch for input_embedding.continuous_projection.weight: copying a param with shape torch.Size([20, 13]) from checkpoint, the shape in current model is torch.Size([24, 13]).\n\tsize mismatch for input_embedding.continuous_projection.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for input_embedding.categorical_embeddings.0.weight: copying a param with shape torch.Size([10, 4]) from checkpoint, the shape in current model is torch.Size([10, 8]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 99\u001b[0m\n\u001b[1;32m     95\u001b[0m start_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# ============= Make Predictions =============\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m \u001b[43mpredict_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHECKPOINT_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprice_series\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombined_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# combined_prices,\u001b[39;49;00m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43maveraged_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maveraged_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_FUTURE_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_PARAMS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multi_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUSE_MULTI_HORIZON\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstability_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTABILITY_THRESHOLD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Max % daily move - decrease for more stability\u001b[39;49;00m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDAMPENING_FACTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Stronger dampening - decrease for more stability\u001b[39;49;00m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mewma_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEWMA_ALPHA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# More smoothing - decrease for more stability\u001b[39;49;00m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhorizon_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHORIZON_WEIGHTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# [0.5, 0.5], # [0.3, 0.7],\u001b[39;49;00m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_forcing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUSE_FORCING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforcing_halflife\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFORCING_HALFLIFE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEMPERATURE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_sampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUSE_SAMPLING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_scaling_power\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRETURN_SCALING_POWER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_uncertainty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBASE_UNCERTAINTY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43muncertainty_growth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUNCERTAINTY_GROWTH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_uncertainty_single\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_UNCERTAINTY_SINGLE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_uncertainty_multi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_UNCERTAINTY_MULTI\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43muncertainty_damping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUNCERTAINTY_DAMPING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing checkpoint: \u001b[39m\u001b[38;5;124m\"\u001b[39m, CHECKPOINT_PATH)\n",
      "File \u001b[0;32m/Volumes/ExtremeSSD/repos/FINPAK/src/finpak/transformer_predictions/inference_v5.py:486\u001b[0m, in \u001b[0;36mpredict_from_checkpoint\u001b[0;34m(checkpoint_path, price_series, start_indices, averaged_indices, n_steps, config, model_params, device, use_multi_horizon, horizon_weights, use_forcing, forcing_halflife, debug, stability_threshold, dampening_factor, use_ewma_smoothing, ewma_alpha, temperature, use_sampling, return_scaling_power, base_uncertainty, uncertainty_growth, max_uncertainty_single, max_uncertainty_multi, uncertainty_damping)\u001b[0m\n\u001b[1;32m    483\u001b[0m total_required_history \u001b[38;5;241m=\u001b[39m sequence_length \u001b[38;5;241m+\u001b[39m max_lookback\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_and_predict\u001b[39m(indices):\n\u001b[1;32m    493\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to validate indices and make predictions\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/ExtremeSSD/repos/FINPAK/src/finpak/transformer_predictions/inference_v5.py:35\u001b[0m, in \u001b[0;36mload_model_from_checkpoint\u001b[0;34m(checkpoint_path, model_params, device)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Load checkpoint\u001b[39;00m\n\u001b[1;32m     34\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(checkpoint_path, map_location\u001b[38;5;241m=\u001b[39mdevice, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 35\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/venvs/finpak/lib/python3.12/site-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TimeSeriesDecoder:\n\tUnexpected key(s) in state_dict: \"input_embedding.categorical_embeddings.1.weight\", \"input_embedding.categorical_embeddings.2.weight\". \n\tsize mismatch for input_embedding.continuous_projection.weight: copying a param with shape torch.Size([20, 13]) from checkpoint, the shape in current model is torch.Size([24, 13]).\n\tsize mismatch for input_embedding.continuous_projection.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for input_embedding.categorical_embeddings.0.weight: copying a param with shape torch.Size([10, 4]) from checkpoint, the shape in current model is torch.Size([10, 8])."
     ]
    }
   ],
   "source": [
    "\n",
    "# Prediction Parameters\n",
    "N_FUTURE_STEPS = 20\n",
    "USE_SAMPLING = True\n",
    "TEMPERATURE = 0.05 # 0.3 # 0.1  # Controls prediction randomness (higher = more random) - temporarily set to 0.7\n",
    "\n",
    "# Stability Parameters\n",
    "STABILITY_THRESHOLD = 0.02 # 0.015  # Max allowed daily return (decrease for more stability)\n",
    "DAMPENING_FACTOR = 0.95  #   0.65    # Price dampening (decrease for more stability)\n",
    "EWMA_ALPHA = 0.85 # 0.2          # Price smoothing (decrease for more stability)\n",
    "RETURN_SCALING_POWER = 0.001 # 0.55 1 # Increase to scale down longer term returns more and decrease to increase their impact\n",
    "\n",
    "# Uncertainty Parameters - higher uncertainty = wider cones\n",
    "BASE_UNCERTAINTY = 0.00001 # 0.0005 # Initial uncertainty level (as fraction)\n",
    "UNCERTAINTY_GROWTH = 0.000001 # 0.00025 # Rate at which uncertainty grows per step (as fraction)\n",
    "MAX_UNCERTAINTY_SINGLE = 0.03 # 0.1 # Maximum bounds for single horizon (±20%)\n",
    "MAX_UNCERTAINTY_MULTI = 0.08 # 0.25 # Maximum bounds for multi horizon (±50%)\n",
    "UNCERTAINTY_DAMPING = 0.99 # 0.05 # Dampening factor for uncertainty growth - higher is more dampening = narrower cones\n",
    "\n",
    "# Multi-horizon Parameters\n",
    "USE_MULTI_HORIZON = True # False # Ideally set to True\n",
    "HORIZON_WEIGHTS = None     # Optional: e.g. [0.5, 0.5] to weight different prediction horizons\n",
    "\n",
    "# Teacher Forcing Parameters\n",
    "USE_FORCING = False\n",
    "FORCING_HALFLIFE = 3.0\n",
    "\n",
    "# Index Generation Parameters\n",
    "TOP_LEVEL_INDICES = np.arange(0, 660, 45).tolist()\n",
    "OFFSET_STEPS = [-1, -2, -3 -4, -5, -1, -2, -3 -4, -5, -1, -2, -3 -4, -5, -1, -2, -3 -4, -5] # [-5, -10, -15, -20, -25]\n",
    "\n",
    "# ============= Config-Derived Parameters =============\n",
    "# Load config\n",
    "CONFIG = all_configs[CONFIG_NAME]\n",
    "MODEL_PARAMS = CONFIG['model_params'].copy()\n",
    "MODEL_PARAMS.pop('dropout', None)  # Remove dropout for inference\n",
    "\n",
    "# Get sequence and feature parameters from config\n",
    "sequence_length = CONFIG['data_params']['sequence_length']\n",
    "return_periods = CONFIG['data_params']['return_periods']\n",
    "sma_periods = CONFIG['data_params']['sma_periods']\n",
    "target_periods = CONFIG['data_params']['target_periods']\n",
    "momentum_periods = CONFIG['data_params']['momentum_periods']\n",
    "\n",
    "# Calculate input dimension\n",
    "d_input = 0\n",
    "d_input += len(return_periods)  # Return features\n",
    "d_input += len(sma_periods)     # SMA features\n",
    "if CONFIG['data_params']['use_momentum']:\n",
    "    d_input += len(CONFIG['data_params']['momentum_periods'])\n",
    "if CONFIG['data_params']['use_volatility']:\n",
    "    d_input += len(return_periods)\n",
    "\n",
    "# Calculate output dimension\n",
    "n_outputs = len(target_periods)\n",
    "\n",
    "# Update model parameters\n",
    "\n",
    "MODEL_PARAMS['d_continuous'] = d_input\n",
    "MODEL_PARAMS['n_categorical'] = 1\n",
    "MODEL_PARAMS['n_bins'] = CONFIG['data_params']['price_change_bins']['n_bins']\n",
    "MODEL_PARAMS['n_outputs'] = n_outputs\n",
    "\n",
    "print(MODEL_PARAMS)\n",
    "\n",
    "# ============= Index Generation =============\n",
    "# Calculate required history\n",
    "max_lookback = max([\n",
    "    max(sma_periods) if sma_periods else 0,\n",
    "    max(momentum_periods) if momentum_periods else 0,\n",
    "    max(return_periods),\n",
    "    max(target_periods)\n",
    "])\n",
    "total_required_history = sequence_length + max_lookback\n",
    "\n",
    "# Find last valid index\n",
    "last_valid_idx = torch.where(torch.isfinite(combined_prices))[0][-1].item()\n",
    "\n",
    "# Generate valid start indices\n",
    "start_indices = []\n",
    "for base_idx in TOP_LEVEL_INDICES:\n",
    "    for offset in OFFSET_STEPS:\n",
    "        idx = last_valid_idx - (base_idx + abs(offset))\n",
    "        if idx >= total_required_history:\n",
    "            start_indices.append(idx)\n",
    "\n",
    "averaged_indices = []\n",
    "for base_idx in TOP_LEVEL_INDICES:\n",
    "    sub_indices = []\n",
    "    for offset in OFFSET_STEPS:\n",
    "        idx = last_valid_idx - (base_idx + abs(offset))\n",
    "        if idx >= total_required_history:\n",
    "            sub_indices.append(idx)\n",
    "    averaged_indices.append(sub_indices)\n",
    "\n",
    "start_indices = None\n",
    "\n",
    "\n",
    "# ============= Make Predictions =============\n",
    "predict_from_checkpoint(\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    price_series=combined_prices, # combined_prices,\n",
    "    start_indices=start_indices,\n",
    "    averaged_indices=averaged_indices,\n",
    "    n_steps=N_FUTURE_STEPS,\n",
    "    config=CONFIG,\n",
    "    model_params=MODEL_PARAMS,\n",
    "    use_multi_horizon=USE_MULTI_HORIZON,\n",
    "    stability_threshold=STABILITY_THRESHOLD,  # Max % daily move - decrease for more stability\n",
    "    dampening_factor=DAMPENING_FACTOR,  # Stronger dampening - decrease for more stability\n",
    "    ewma_alpha=EWMA_ALPHA,  # More smoothing - decrease for more stability\n",
    "    horizon_weights=HORIZON_WEIGHTS, # [0.5, 0.5], # [0.3, 0.7],\n",
    "    use_forcing=USE_FORCING,\n",
    "    forcing_halflife=FORCING_HALFLIFE,\n",
    "    temperature=TEMPERATURE,\n",
    "    use_sampling=USE_SAMPLING,\n",
    "    return_scaling_power=RETURN_SCALING_POWER,\n",
    "    base_uncertainty=BASE_UNCERTAINTY,\n",
    "    uncertainty_growth=UNCERTAINTY_GROWTH,\n",
    "    max_uncertainty_single=MAX_UNCERTAINTY_SINGLE,\n",
    "    max_uncertainty_multi=MAX_UNCERTAINTY_MULTI,\n",
    "    uncertainty_damping=UNCERTAINTY_DAMPING,\n",
    "    debug=False,\n",
    ")\n",
    "print(\"Using checkpoint: \", CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(combined_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<class 'torch.Tensor'>}\n"
     ]
    }
   ],
   "source": [
    "typs = [type(x) for x in combined_prices]\n",
    "print(set(typs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.4508e+01, 4.3961e+01, 4.3590e+01,  ..., 1.2928e+05, 1.2826e+05,\n",
       "        1.2939e+05])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(torch.isnan(combined_prices), torch.zeros_like(combined_prices), combined_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.4508e+01, 4.3961e+01, 4.3590e+01,  ..., 1.2928e+05, 1.2826e+05,\n",
       "        1.2939e+05])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(torch.isinf(combined_prices), torch.zeros_like(combined_prices), combined_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(42.6732),\n",
       " tensor(130504.1250),\n",
       " tensor([44.5077, 43.9606, 43.5900, 43.4841, 43.6605, 44.1724, 44.6842, 44.8430,\n",
       "         44.7459, 45.7519, 46.1136, 45.8666, 45.8754, 46.3695, 46.1842, 46.9607,\n",
       "         46.9607, 47.2607, 47.2343, 47.4725]),\n",
       " tensor([123724.3203, 123363.8828, 124937.6250, 128331.3281, 130351.8125,\n",
       "         130504.1250, 130427.9766, 130191.8984, 130024.3828, 129120.7422,\n",
       "         126044.3281, 126920.0391, 127793.2109, 127719.6094, 128179.0391,\n",
       "         128384.6406, 128587.7031, 129278.1172, 128260.2578, 129387.2656]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(combined_prices), max(combined_prices), combined_prices[:20], combined_prices[-20:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Finpak",
   "language": "python",
   "name": "finpak"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
